#!/bin/bash

url=$1

if [ -z "$BUILD_CACHE_BUCKET" ]; then
	exit 1
fi

if [ -z $url ]; then
	exit 0
fi



get_s3() {
	s3path=$1
	filename=$2
	aws s3 cp $s3path $filename 1>&2
}

put_s3() {
	s3path=$1
	filename=$2
	aws s3 cp --dryrun $filename $s3path 1>&2
	aws s3 cp $filename $s3path 1>&2
}


urlid=$(echo -n "$url" | md5sum)

if [ -n "$WORKDIR" ]; then
	mkdir -p $WORKDIR/tmp
	TMPDIR=$WORKDIR/tmp
	export TMPDIR
fi

tempfile=$(mktemp)

cached_url="s3://${BUILD_CACHE_BUCKET}/cache/$urlid"

get_s3 $cached_url $tempfile

if [[ $? -gt 0 || -s "$tempfile" ]]; then
	>&2 echo "Retrieving $@ into build cache (via $tempfile)"
	curl --progress-bar $@ -o $tempfile
	if [ $? -gt 0 ]; then
		>&2 echo "Failure to retrieve file"
		exit 1
	fi
	>&2 echo "Copying $tempfile to $cached_url"
	put_s3 $cached_url $tempfile
	if [ $? -gt 0 ]; then
		>&2 echo "Could not cache file"
		exit 1
	fi
	>&2 echo "Copied file for caching"
fi

cat $tempfile && rm $tempfile